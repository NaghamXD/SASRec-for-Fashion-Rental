import re
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# Paste your log content into this string variable
log_content = """
Model Drop_out=0.2 
Learning rate of the images and tags embeddings=0.01
epoch (val_ndcg, val_hr) (test_ndcg, test_hr)
20 (np.float64(0.18110084029342619), 0.35408366533864544) (np.float64(0.18738436204445247), 0.3545816733067729) alpha_v:0.3842 alpha_t:0.3064
40 (np.float64(0.19971107090291265), 0.38197211155378485) (np.float64(0.19258745905192234), 0.36354581673306774) alpha_v:0.5572 alpha_t:0.4516
60 (np.float64(0.19221570623882023), 0.3520916334661355) (np.float64(0.1806229119383563), 0.3386454183266932) alpha_v:0.5910 alpha_t:0.4864
80 (np.float64(0.18299344681862695), 0.3351593625498008) (np.float64(0.17795960813019326), 0.3346613545816733) alpha_v:0.6310 alpha_t:0.4682
100 (np.float64(0.1808795105292652), 0.3386454183266932) (np.float64(0.1754686367293618), 0.32768924302788843) alpha_v:0.6118 alpha_t:0.5011
120 (np.float64(0.1686034114440217), 0.30677290836653387) (np.float64(0.16727940012741604), 0.30776892430278885) alpha_v:0.6403 alpha_t:0.4634
140 (np.float64(0.1732634755081639), 0.32121513944223107) (np.float64(0.16867388983507545), 0.30776892430278885) alpha_v:0.6392 alpha_t:0.4454
Model Drop_out=0.7
Learning rate of the images and tags embeddings=0.001
epoch (val_ndcg, val_hr) (test_ndcg, test_hr)
20 (np.float64(0.16997409201682404), 0.3436254980079681) (np.float64(0.17085597720502185), 0.3376494023904382) alpha_v:0.2966 alpha_t:-0.1659
40 (np.float64(0.21184198801873205), 0.3989043824701195) (np.float64(0.21705344958376344), 0.4038844621513944) alpha_v:0.3843 alpha_t:-0.2154
60 (np.float64(0.23582268824491698), 0.44272908366533864) (np.float64(0.2381280040892393), 0.4442231075697211) alpha_v:0.4031 alpha_t:-0.2487
80 (np.float64(0.24007257751020594), 0.43774900398406374) (np.float64(0.2420986508983168), 0.4457171314741036) alpha_v:0.4379 alpha_t:-0.2739
100 (np.float64(0.2423270409182921), 0.4447211155378486) (np.float64(0.2541628921025779), 0.45169322709163345) alpha_v:0.4690 alpha_t:-0.2998
120 (np.float64(0.24911710492442277), 0.43675298804780877) (np.float64(0.24557003822176307), 0.4457171314741036) alpha_v:0.4610 alpha_t:-0.3049
140 (np.float64(0.247871361143232), 0.449203187250996) (np.float64(0.2496358519261109), 0.44671314741035856) alpha_v:0.4900 alpha_t:-0.3337
160 (np.float64(0.2566280920644061), 0.4497011952191235) (np.float64(0.25305878347203004), 0.4581673306772908) alpha_v:0.4750 alpha_t:-0.3494
180 (np.float64(0.25001568604935104), 0.4506972111553785) (np.float64(0.2511757285998418), 0.4457171314741036) alpha_v:0.4804 alpha_t:-0.3590
200 (np.float64(0.25071397129210676), 0.4392430278884462) (np.float64(0.2527077449907132), 0.44721115537848605) alpha_v:0.5163 alpha_t:-0.3627
220 (np.float64(0.2559435880014743), 0.450199203187251) (np.float64(0.25808629918563525), 0.4531872509960159) alpha_v:0.5231 alpha_t:-0.3798
240 (np.float64(0.2564471525045326), 0.4447211155378486) (np.float64(0.2528302825839606), 0.44721115537848605) alpha_v:0.5196 alpha_t:-0.3889
260 (np.float64(0.25071767502957143), 0.4437250996015936) (np.float64(0.2522411710184611), 0.44621513944223107) alpha_v:0.5402 alpha_t:-0.3978
280 (np.float64(0.2649512889671456), 0.45717131474103584) (np.float64(0.2519714992681816), 0.4442231075697211) alpha_v:0.5526 alpha_t:-0.3917
300 (np.float64(0.25205139288024353), 0.44621513944223107) (np.float64(0.25468164520774894), 0.44322709163346613) alpha_v:0.5291 alpha_t:-0.3987
320 (np.float64(0.2543937876072736), 0.44272908366533864) (np.float64(0.251024566563461), 0.44123505976095617) alpha_v:0.5753 alpha_t:-0.4379
340 (np.float64(0.25155186753244463), 0.4437250996015936) (np.float64(0.2491693435999689), 0.44123505976095617) alpha_v:0.5418 alpha_t:-0.4115
360 (np.float64(0.25318019967895505), 0.44272908366533864) (np.float64(0.25074713372775204), 0.4357569721115538) alpha_v:0.5709 alpha_t:-0.4304
380 (np.float64(0.25517306309750165), 0.449203187250996) (np.float64(0.2494199486935097), 0.44173306772908366) alpha_v:0.5619 alpha_t:-0.4316

Model Drop_out=0.2 
Learning rate of the images and tags embeddings=0.001
epoch (val_ndcg, val_hr) (test_ndcg, test_hr)
20 (np.float64(0.18908151002533807), 0.36254980079681276) (np.float64(0.1819129443268047), 0.34213147410358563) alpha_v:0.3506 alpha_t:0.2343
40 (np.float64(0.1924398083214144), 0.3565737051792829) (np.float64(0.18777944529578597), 0.3555776892430279) alpha_v:0.4985 alpha_t:0.3543
60 (np.float64(0.19059633368666917), 0.3500996015936255) (np.float64(0.17712792922093873), 0.3436254980079681) alpha_v:0.5581 alpha_t:0.3912
80 (np.float64(0.17967182822247568), 0.33167330677290835) (np.float64(0.16190167951685744), 0.31225099601593626) alpha_v:0.5663 alpha_t:0.3965
100 (np.float64(0.1794774942101489), 0.3331673306772908) (np.float64(0.1624834223066539), 0.3112549800796813) alpha_v:0.5723 alpha_t:0.3954
120 (np.float64(0.17889652771535586), 0.32221115537848605) (np.float64(0.16677377196373347), 0.30727091633466136) alpha_v:0.5657 alpha_t:0.3951
140 (np.float64(0.17359524564440765), 0.3187250996015936) (np.float64(0.1651611699039239), 0.31274900398406374) alpha_v:0.5586 alpha_t:0.3975

Model Drop_out=0.7 
Learning rate of the images and tags embeddings=0.01
epoch (val_ndcg, val_hr) (test_ndcg, test_hr)
20 (np.float64(0.16652555213708556), 0.33167330677290835) (np.float64(0.15783330916413169), 0.3062749003984064) alpha_v:0.2189 alpha_t:0.1409
40 (np.float64(0.21661379206304932), 0.4038844621513944) (np.float64(0.21285891330203718), 0.39591633466135456) alpha_v:0.3220 alpha_t:0.2090
60 (np.float64(0.22786068537890056), 0.425796812749004) (np.float64(0.23692708650357594), 0.43326693227091634) alpha_v:0.3664 alpha_t:0.2454
80 (np.float64(0.23512151411857568), 0.4312749003984064) (np.float64(0.24400189699553912), 0.4452191235059761) alpha_v:0.3970 alpha_t:0.2681
100 (np.float64(0.24118139559434848), 0.4442231075697211) (np.float64(0.252647622588597), 0.4487051792828685) alpha_v:0.4255 alpha_t:0.2824
120 (np.float64(0.25026414121568136), 0.4497011952191235) (np.float64(0.2451436563860988), 0.43824701195219123) alpha_v:0.4327 alpha_t:0.2940
140 (np.float64(0.24935256919933188), 0.45169322709163345) (np.float64(0.2493521560236755), 0.44721115537848605) alpha_v:0.4436 alpha_t:0.3014
160 (np.float64(0.2558724832392965), 0.44721115537848605) (np.float64(0.25419053932856034), 0.4487051792828685) alpha_v:0.4535 alpha_t:0.3195
180 (np.float64(0.2521736893048019), 0.4487051792828685) (np.float64(0.2549149926944237), 0.45219123505976094) alpha_v:0.4688 alpha_t:0.3309
200 (np.float64(0.25683671817300907), 0.45169322709163345) (np.float64(0.2589220252566755), 0.4442231075697211) alpha_v:0.4699 alpha_t:0.3352
220 (np.float64(0.2505457464933973), 0.43276892430278885) (np.float64(0.24826874838190316), 0.4407370517928287) alpha_v:0.4751 alpha_t:0.3371
240 (np.float64(0.2596056150847804), 0.4531872509960159) (np.float64(0.25408733633965475), 0.45219123505976094) alpha_v:0.4915 alpha_t:0.3491
260 (np.float64(0.25391717320347246), 0.4352589641434263) (np.float64(0.25883847750891503), 0.44272908366533864) alpha_v:0.4984 alpha_t:0.3507
280 (np.float64(0.25822165997942464), 0.44671314741035856) (np.float64(0.26153227439407944), 0.4586653386454183) alpha_v:0.5066 alpha_t:0.3635
300 (np.float64(0.25397276525067497), 0.44621513944223107) (np.float64(0.25484977665741726), 0.44223107569721115) alpha_v:0.5079 alpha_t:0.3731
320 (np.float64(0.25324966646917396), 0.4397410358565737) (np.float64(0.2504332679901914), 0.44272908366533864) alpha_v:0.5229 alpha_t:0.3680
340 (np.float64(0.25745065993281013), 0.44322709163346613) (np.float64(0.26178475896923564), 0.4536852589641434) alpha_v:0.5263 alpha_t:0.3723
360 (np.float64(0.25774189346589926), 0.4437250996015936) (np.float64(0.25282815057077024), 0.4437250996015936) alpha_v:0.5327 alpha_t:0.3902
380 (np.float64(0.25848011641683294), 0.45219123505976094) (np.float64(0.2560785564356755), 0.4497011952191235) alpha_v:0.5341 alpha_t:0.3940
400 (np.float64(0.255225258796204), 0.44123505976095617) (np.float64(0.25939090431788664), 0.450199203187251) alpha_v:0.5447 alpha_t:0.3940
420 (np.float64(0.2570263110644911), 0.4392430278884462) (np.float64(0.265858063391958), 0.45119521912350596) alpha_v:0.5517 alpha_t:0.3975
440 (np.float64(0.2605794457816794), 0.4442231075697211) (np.float64(0.25794436727043174), 0.449203187250996) alpha_v:0.5567 alpha_t:0.3963
460 (np.float64(0.2526203836372213), 0.4307768924302789) (np.float64(0.25919337191881664), 0.44721115537848605) alpha_v:0.5579 alpha_t:0.4098
480 (np.float64(0.2513357459385241), 0.43675298804780877) (np.float64(0.2592996390444626), 0.44770916334661354) alpha_v:0.5667 alpha_t:0.4082
500 (np.float64(0.252647088628074), 0.4292828685258964) (np.float64(0.2633338896250314), 0.450199203187251) alpha_v:0.5681 alpha_t:0.4026
520 (np.float64(0.251682076487505), 0.42778884462151395) (np.float64(0.259959781886565), 0.43774900398406374) alpha_v:0.5664 alpha_t:0.4111
540 (np.float64(0.26137003486078125), 0.44173306772908366) (np.float64(0.2604590872375496), 0.449203187250996) alpha_v:0.5706 alpha_t:0.4188
560 (np.float64(0.25604541125410485), 0.4352589641434263) (np.float64(0.2561498584627319), 0.4437250996015936) alpha_v:0.5778 alpha_t:0.4213
580 (np.float64(0.2549419905935509), 0.4387450199203187) (np.float64(0.2570844426343755), 0.4302788844621514) alpha_v:0.5862 alpha_t:0.4267
600 (np.float64(0.25176563064221913), 0.4342629482071713) (np.float64(0.2514111698333524), 0.4347609561752988) alpha_v:0.5796 alpha_t:0.4340
620 (np.float64(0.2544034517291576), 0.4362549800796813) (np.float64(0.25452717689216336), 0.4347609561752988) alpha_v:0.5835 alpha_t:0.4396
640 (np.float64(0.2554738190570681), 0.44173306772908366) (np.float64(0.25012054354438984), 0.4342629482071713) alpha_v:0.5927 alpha_t:0.4398
"""

def parse_log(content):
    data = []
    current_dropout = None
    current_lr = None
    
    # Regex patterns
    p_dropout = r"Model Drop_out=([0-9\.]+)"
    p_lr = r"Learning rate.*=([0-9\.]+)"
    # Matches: epoch (val_n, val_h) (test_n, test_h)
    p_metrics = r"(\d+) \(np\.float64\(([\d\.]+)\), ([\d\.]+)\) \(np\.float64\(([\d\.]+)\), ([\d\.]+)\)"

    for line in content.strip().split('\n'):
        # Check for Config Headers
        if "Model Drop_out" in line:
            current_dropout = float(re.search(p_dropout, line).group(1))
        elif "Learning rate" in line:
            current_lr = float(re.search(p_lr, line).group(1))
        
        # Check for Metrics
        elif "(np.float64" in line:
            match = re.search(p_metrics, line)
            if match:
                data.append({
                    'Epoch': int(match.group(1)),
                    'Test_NDCG': float(match.group(4)),
                    'Test_HR': float(match.group(5)),
                    'Config': f"Drop={current_dropout}, LR={current_lr}"
                })
    return pd.DataFrame(data)

# 1. Parse Data
# If reading from a file, use: with open('Drop.docx', 'r') as f: log_content = f.read()
df = parse_log(log_content)

# 2. Setup Plot Style
sns.set_theme(style="whitegrid")
fig, axes = plt.subplots(1, 2, figsize=(16, 6))

# 3. Plot Test NDCG
sns.lineplot(ax=axes[0], data=df, x='Epoch', y='Test_NDCG', hue='Config', style='Config', markers=True, dashes=False)
axes[0].set_title('Test NDCG per Epoch', fontsize=14, fontweight='bold')
axes[0].set_ylabel('NDCG', fontsize=12)

# 4. Plot Test Hit Rate (HR)
sns.lineplot(ax=axes[1], data=df, x='Epoch', y='Test_HR', hue='Config', style='Config', markers=True, dashes=False)
axes[1].set_title('Test Hit Rate (HR) per Epoch', fontsize=14, fontweight='bold')
axes[1].set_ylabel('Hit Rate', fontsize=12)

plt.tight_layout()
plt.show()